{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet():\n",
    "    postingList=[['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],\n",
    "                 ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n",
    "                 ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],\n",
    "                 ['stop', 'posting', 'stupid', 'worthless', 'garbage'],\n",
    "                 ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],\n",
    "                 ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]\n",
    "    classVec = [0,1,0,1,0,1]\n",
    "    return postingList,classVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "postingList, classVec = loadDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createVocabList(dataSet):\n",
    "    vocabSet = set([])\n",
    "    for data in dataSet:\n",
    "        vocabSet = vocabSet | set(data)\n",
    "    return list(vocabSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#词集，在该集合种，每个单词出现就记为1\n",
    "def setOfWord2Vec(vocabList, inputSet):\n",
    "    returnVec = [0] * len(vocabList)\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            returnVec[vocabList.index(word)] = 1\n",
    "        else:\n",
    "            print(\"the word : %s is not in my vocabulary!\"%word)\n",
    "    return returnVec\n",
    "\n",
    "#词袋，在该模型种，单词出现一次就+1\n",
    "def bagOfWord2Vec(vocabList, inputSet):\n",
    "    returnVec = [0] * len(vocabList)\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            returnVec[vocabList.index(word)] += 1\n",
    "        else:\n",
    "            print(\"the word : %s is not in my vocabulary!\"%word)\n",
    "    return returnVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the word : cat is not in my vocabulary!\n",
      "the word : pig is not in my vocabulary!\n"
     ]
    }
   ],
   "source": [
    "#词集函数小测试\n",
    "wordBag = createVocabList(postingList)\n",
    "vec = setOfWord2Vec(wordBag, ['food', 'cat', 'pig', 'I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainBayes(trainMat, category):\n",
    "    numTrain = len(trainMat)\n",
    "    numFeat = len(trainMat[0])\n",
    "    probA = sum(category)/float(numTrain)\n",
    "    #防止下溢\n",
    "#     p0Num = np.zeros(numFeat)\n",
    "#     p1Num = np.zeros(numFeat)\n",
    "#     p0Sum = 0.0\n",
    "#     p1Sum = 0.0\n",
    "    p0Num = np.ones(numFeat)\n",
    "    p1Num = np.ones(numFeat)\n",
    "    p0Sum = 2.0\n",
    "    p1Sum = 2.0\n",
    "    for i in range(numTrain):\n",
    "        if category[i] == 1:\n",
    "            p1Num += trainMat[i]\n",
    "            p1Sum += sum(trainMat[i])\n",
    "        else:\n",
    "            p0Num += trainMat[i]\n",
    "            p0Sum += sum(trainMat[i])\n",
    "    p1Vec = np.log(p1Num / p1Sum)\n",
    "    p0Vec = np.log(p0Num / p0Sum)\n",
    "    return probA, p0Vec, p1Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将训练数据转换为向量形式，用0 1表示\n",
    "trainMat = []\n",
    "for row in postingList:\n",
    "    trainMat.append(setOfWord2Vec(wordBag, row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pA, p0, p1 = trainBayes(trainMat, classVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict\n",
    "def predict(wordVec, p0Vec, p1Vec, pA):\n",
    "    #侮辱\n",
    "    p1 = sum(p1Vec * wordVec) + np.log(pA)\n",
    "    #非侮辱\n",
    "    p0 = sum(p0Vec * wordVec) + np.log(1-pA)\n",
    "    if p1 > p0:\n",
    "        return 1;\n",
    "    else:\n",
    "        return 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the word : you is not in my vocabulary!\n",
      "the prediction is : 0\n",
      "the prediction is : 1\n"
     ]
    }
   ],
   "source": [
    "testWord = ['I', 'love', 'you']\n",
    "testVec = np.array(setOfWord2Vec(wordBag, testWord))\n",
    "print(\"the prediction is : %d\"%predict(testVec, p0, p1, pA))\n",
    "testWord = ['dog', 'stupid', 'posting']\n",
    "testVec = np.array(setOfWord2Vec(wordBag, testWord))\n",
    "print(\"the prediction is : %d\"%predict(testVec, p0, p1, pA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.将所有词放入一个集合中\n",
    "2.将每个词向量转换为0 1表示的向量（在1中出现的词就为1，未出现即未0），放入一个矩阵中，构成训练数据。\n",
    "3.训练：计算p(c)的概率，统计分类后，每个单词在各自的分类中出现的次数a（a为一个数组），统计在该分类下出现的所有的单词数量b，计算a/b，得到每个单词出现的概率p。\n",
    "4.计算两个分类下的p * p(c),得到后验概率。输出较大的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
