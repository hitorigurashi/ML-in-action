# 回归
1.线性回归
  误差函数：Σ（y - x.T*w）**2    也可以写成： (y-xw).T(y-xw)
  对w求导： what = (x.T*x).I*x.T*y

2.局部加权线性回归 locally weighted linear regression
  给待测点附近的每个点赋予一定的权重
  此时 what  = (x.T*w*x).I*x.T*w*y
  使用高斯核函数  w(i,i) = exp(abs(xi - x)/(-2*k**2))
  k太小时，会造成过拟合

3.岭回归 ridge regression
  损失函数： j(θ) = 1/(2*m) * Σ(y_pred - y)**2 + λ*Σθ**2
  引用的为L2范数惩罚项

4.lasso回归
  损失函数： j(θ) = 1/(2*m) * Σ(y_pred - y)**2 + λ*Σabs(θ)
  L1范数惩罚项
  
lambda 选取过大，会把所有参数θ均最小化，造成欠拟合，如果lambda选取国小，会导致对过拟合问题解决不当
lasso回归能够使得损失函数中的许多θ均变成0，这点要优于岭回归，因为岭回归是要所有的theta均存在，这样计算量lasso回归将远小于岭回归
  
